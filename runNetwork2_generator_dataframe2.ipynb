{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\arung\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters here \n",
    "INPUT_SIZE = 256\n",
    "mapping = {0:'normal', 1:'other'}\n",
    "NUMCLASSES = len(mapping)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "folder = r'C:\\Users\\arung\\OneDrive\\Desktop\\COVID 19 Chest Xray\\nih'\n",
    "\n",
    "trainFolder = folder + r'\\train'\n",
    "valFolder = folder + r'\\val'\n",
    "testFolder = folder + r'\\test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def preprocess(img):\n",
    "    # Contrast stretching\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                featurewise_center=False,\n",
    "                                samplewise_center=False,\n",
    "                                featurewise_std_normalization=False,\n",
    "                                samplewise_std_normalization=False,\n",
    "                                zca_whitening=False,\n",
    "                                zca_epsilon=1e-06,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0.0,\n",
    "                                height_shift_range=0.0,\n",
    "                                brightness_range=None,\n",
    "                                shear_range=0.0,\n",
    "                                zoom_range=0.0,\n",
    "                                channel_shift_range=0.0,\n",
    "                                fill_mode=\"nearest\",\n",
    "                                cval=0.0,\n",
    "                                horizontal_flip=False,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=None,\n",
    "                                preprocessing_function=preprocess,\n",
    "                                data_format=None,\n",
    "                                validation_split=0.2,\n",
    "                                dtype=None,\n",
    "                            )\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                featurewise_center=False,\n",
    "                                samplewise_center=False,\n",
    "                                featurewise_std_normalization=False,\n",
    "                                samplewise_std_normalization=False,\n",
    "                                zca_whitening=False,\n",
    "                                zca_epsilon=1e-06,\n",
    "                                rotation_range=0,\n",
    "                                width_shift_range=0.0,\n",
    "                                height_shift_range=0.0,\n",
    "                                brightness_range=None,\n",
    "                                shear_range=0.0,\n",
    "                                zoom_range=0.0,\n",
    "                                channel_shift_range=0.0,\n",
    "                                fill_mode=\"nearest\",\n",
    "                                cval=0.0,\n",
    "                                horizontal_flip=False,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=None,\n",
    "                                preprocessing_function=preprocess,\n",
    "                                data_format=None,\n",
    "                                validation_split=0.2,\n",
    "                                dtype=None,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal    5061\n",
      "other     3568\n",
      "Name: label, dtype: int64\n",
      "Found 6904 validated image filenames belonging to 2 classes.\n",
      "Found 1725 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(folder + r'\\allfiles.csv')\n",
    "df = df[df.label!='pneumonia']\n",
    "# This next line is to use only 10% of the data\n",
    "df = df.sample(n = df.shape[0]//10)\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "                                            dataframe=df,\n",
    "                                            directory='',\n",
    "                                            x_col=\"filename\",\n",
    "                                            y_col=\"label\",\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=None,\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='training',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            validate_filenames=True\n",
    "                                        )\n",
    "\n",
    "validation_set = test_datagen.flow_from_dataframe( dataframe=df,\n",
    "                                            directory='',\n",
    "                                            x_col=\"filename\",\n",
    "                                            y_col=\"label\",\n",
    "                                            weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=None,\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='validation',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            validate_filenames=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arung\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      11648     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 64)      165952    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 256)       819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 11,000,770\n",
      "Trainable params: 11,000,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=[INPUT_SIZE,INPUT_SIZE,3])) #keras will internally add batch dimension\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=11,strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=9,strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=7,strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=512,kernel_size=3,strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(NUMCLASSES,activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.00002), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "WARNING:tensorflow:From C:\\Users\\arung\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 133s 616ms/step - loss: 0.6929 - accuracy: 0.5846 - val_loss: 0.6928 - val_accuracy: 0.5942\n",
      "Saved model to disk after 1 epochs.\n",
      "Epoch 1\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 154s 713ms/step - loss: 0.6924 - accuracy: 0.5846 - val_loss: 0.6917 - val_accuracy: 0.5942\n",
      "Saved model to disk after 2 epochs.\n",
      "Epoch 2\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 141s 654ms/step - loss: 0.6919 - accuracy: 0.5846 - val_loss: 0.6941 - val_accuracy: 0.5942\n",
      "Saved model to disk after 3 epochs.\n",
      "Epoch 3\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 145s 670ms/step - loss: 0.6915 - accuracy: 0.5846 - val_loss: 0.6879 - val_accuracy: 0.5942\n",
      "Saved model to disk after 4 epochs.\n",
      "Epoch 4\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 143s 663ms/step - loss: 0.6910 - accuracy: 0.5846 - val_loss: 0.6917 - val_accuracy: 0.5942\n",
      "Saved model to disk after 5 epochs.\n",
      "Epoch 5\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 144s 665ms/step - loss: 0.6906 - accuracy: 0.5846 - val_loss: 0.6903 - val_accuracy: 0.5942\n",
      "Saved model to disk after 6 epochs.\n",
      "Epoch 6\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 142s 657ms/step - loss: 0.6901 - accuracy: 0.5846 - val_loss: 0.6913 - val_accuracy: 0.5942\n",
      "Saved model to disk after 7 epochs.\n",
      "Epoch 7\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 142s 657ms/step - loss: 0.6897 - accuracy: 0.5846 - val_loss: 0.6910 - val_accuracy: 0.5942\n",
      "Saved model to disk after 8 epochs.\n",
      "Epoch 8\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 147s 680ms/step - loss: 0.6893 - accuracy: 0.5846 - val_loss: 0.6926 - val_accuracy: 0.5942\n",
      "Saved model to disk after 9 epochs.\n",
      "Epoch 9\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 152s 702ms/step - loss: 0.6890 - accuracy: 0.5846 - val_loss: 0.6887 - val_accuracy: 0.5942\n",
      "Saved model to disk after 10 epochs.\n",
      "Epoch 10\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 151s 700ms/step - loss: 0.6886 - accuracy: 0.5846 - val_loss: 0.6841 - val_accuracy: 0.5942\n",
      "Saved model to disk after 11 epochs.\n",
      "Epoch 11\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 149s 690ms/step - loss: 0.6882 - accuracy: 0.5846 - val_loss: 0.6903 - val_accuracy: 0.5942\n",
      "Saved model to disk after 12 epochs.\n",
      "Epoch 12\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 145s 671ms/step - loss: 0.6879 - accuracy: 0.5846 - val_loss: 0.6926 - val_accuracy: 0.5942\n",
      "Saved model to disk after 13 epochs.\n",
      "Epoch 13\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 146s 676ms/step - loss: 0.6876 - accuracy: 0.5846 - val_loss: 0.6979 - val_accuracy: 0.5942\n",
      "Saved model to disk after 14 epochs.\n",
      "Epoch 14\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 145s 672ms/step - loss: 0.6872 - accuracy: 0.5846 - val_loss: 0.6898 - val_accuracy: 0.5942\n",
      "Saved model to disk after 15 epochs.\n",
      "Epoch 15\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 147s 680ms/step - loss: 0.6869 - accuracy: 0.5846 - val_loss: 0.6956 - val_accuracy: 0.5942\n",
      "Saved model to disk after 16 epochs.\n",
      "Epoch 16\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 146s 677ms/step - loss: 0.6866 - accuracy: 0.5846 - val_loss: 0.6926 - val_accuracy: 0.5942\n",
      "Saved model to disk after 17 epochs.\n",
      "Epoch 17\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 144s 666ms/step - loss: 0.6863 - accuracy: 0.5846 - val_loss: 0.6860 - val_accuracy: 0.5942\n",
      "Saved model to disk after 18 epochs.\n",
      "Epoch 18\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 145s 670ms/step - loss: 0.6860 - accuracy: 0.5846 - val_loss: 0.6927 - val_accuracy: 0.5942\n",
      "Saved model to disk after 19 epochs.\n",
      "Epoch 19\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 149s 690ms/step - loss: 0.6857 - accuracy: 0.5846 - val_loss: 0.7000 - val_accuracy: 0.5942\n",
      "Saved model to disk after 20 epochs.\n",
      "Epoch 20\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 160s 741ms/step - loss: 0.6855 - accuracy: 0.5846 - val_loss: 0.6890 - val_accuracy: 0.5942\n",
      "Saved model to disk after 21 epochs.\n",
      "Epoch 21\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 160s 739ms/step - loss: 0.6852 - accuracy: 0.5846 - val_loss: 0.6888 - val_accuracy: 0.5942\n",
      "Saved model to disk after 22 epochs.\n",
      "Epoch 22\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 164s 760ms/step - loss: 0.6849 - accuracy: 0.5846 - val_loss: 0.7094 - val_accuracy: 0.5942\n",
      "Saved model to disk after 23 epochs.\n",
      "Epoch 23\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 149s 689ms/step - loss: 0.6847 - accuracy: 0.5846 - val_loss: 0.6972 - val_accuracy: 0.5942\n",
      "Saved model to disk after 24 epochs.\n",
      "Epoch 24\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 147s 680ms/step - loss: 0.6845 - accuracy: 0.5846 - val_loss: 0.6930 - val_accuracy: 0.5942\n",
      "Saved model to disk after 25 epochs.\n",
      "Epoch 25\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 141s 655ms/step - loss: 0.6842 - accuracy: 0.5846 - val_loss: 0.6885 - val_accuracy: 0.5942\n",
      "Saved model to disk after 26 epochs.\n",
      "Epoch 26\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 137s 635ms/step - loss: 0.6840 - accuracy: 0.5846 - val_loss: 0.6979 - val_accuracy: 0.5942\n",
      "Saved model to disk after 27 epochs.\n",
      "Epoch 27\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 147s 680ms/step - loss: 0.6838 - accuracy: 0.5846 - val_loss: 0.6883 - val_accuracy: 0.5942\n",
      "Saved model to disk after 28 epochs.\n",
      "Epoch 28\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 146s 676ms/step - loss: 0.6836 - accuracy: 0.5846 - val_loss: 0.6732 - val_accuracy: 0.5942\n",
      "Saved model to disk after 29 epochs.\n",
      "Epoch 29\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 2291s 11s/step - loss: 0.6834 - accuracy: 0.5846 - val_loss: 0.6934 - val_accuracy: 0.5942\n",
      "Saved model to disk after 30 epochs.\n",
      "Epoch 30\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 119s 550ms/step - loss: 0.6832 - accuracy: 0.5846 - val_loss: 0.6776 - val_accuracy: 0.5942\n",
      "Saved model to disk after 31 epochs.\n",
      "Epoch 31\n",
      "Epoch 1/1\n",
      "216/216 [==============================] - 118s 547ms/step - loss: 0.6830 - accuracy: 0.5846 - val_loss: 0.6718 - val_accuracy: 0.5942\n",
      "Saved model to disk after 32 epochs.\n",
      "Epoch 32\n",
      "Epoch 1/1\n",
      " 27/216 [==>...........................] - ETA: 1:33 - loss: 0.6829 - accuracy: 0.5845"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#c_weights = {0: 0.4, 1: 0.6}\n",
    "\n",
    "for epoch in range(0,50):\n",
    "    print(\"Epoch\",epoch)\n",
    "    if epoch != 0:\n",
    "        # Load Model Weights\n",
    "        model.load_weights('model-normalized-new.h5')    \n",
    "    history = model.fit_generator(training_set,\n",
    "    steps_per_epoch=len(training_set),\n",
    "                   epochs=1,\n",
    "                   validation_data=validation_set,\n",
    "                   validation_steps = len(validation_set))\n",
    "\n",
    "    model.save_weights(\"model-normalized-new.h5\")\n",
    "    print(\"Saved model to disk after\",epoch+1,\"epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'],color='red')\n",
    "plt.plot(history.history['acc'],color='green')\n",
    "plt.plot(history.history['val_loss'],color='magenta')\n",
    "plt.plot(history.history['val_acc'],color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
